\documentclass[11pt,british]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[backend=biber,style=numeric,citestyle=numeric]{biblatex}
\usepackage{lmodern}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{lscape}
\usepackage{listings}
\usepackage{babel}
\usepackage[justification=centering]{caption}
\usepackage{float}
\usepackage[nomain,acronym,toc,nopostdot]{glossaries}
\usepackage{glossary-longragged}
\usepackage[gen]{eurosym}
\setglossarystyle{super}
\setlength\glsdescwidth{\textwidth}
\makeglossaries

\usepackage{multicol}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% python syntax highlighting

\usepackage{color}
\usepackage{listings}
\usepackage{setspace}

\definecolor{Code}{rgb}{0,0,0}
\definecolor{Decorators}{rgb}{0.5,0.5,0.5}
\definecolor{Numbers}{rgb}{0.5,0,0}
\definecolor{MatchingBrackets}{rgb}{0.25,0.5,0.5}
\definecolor{Keywords}{rgb}{0,0,1}
\definecolor{self}{rgb}{0,0,0}
\definecolor{Strings}{rgb}{0,0.63,0}
\definecolor{Comments}{rgb}{0,0.63,1}
\definecolor{Backquotes}{rgb}{0,0,0}
\definecolor{Classname}{rgb}{0,0,0}
\definecolor{FunctionName}{rgb}{0,0,0}
\definecolor{Operators}{rgb}{0,0,0}
\definecolor{Background}{rgb}{0.98,0.98,0.98}

\lstnewenvironment{python}[1][]{
\lstset{
frame=single,
framesep=2mm, 
belowskip=8pt,
aboveskip=8pt,
% Custom above
numbers=left,
numberstyle=\footnotesize,
numbersep=1em,
xleftmargin=1em,
framextopmargin=2em,
framexbottommargin=2em,
showspaces=false,
showtabs=false,
showstringspaces=false,
frame=l,
tabsize=4,
% Basic
basicstyle=\ttfamily\small\setstretch{1},
backgroundcolor=\color{Background},
language=Python,
% Comments
commentstyle=\color{Comments}\slshape,
% Strings
stringstyle=\color{Strings},
morecomment=[s][\color{Strings}]{"""}{"""},
morecomment=[s][\color{Strings}]{'''}{'''},
% keywords
morekeywords={import,from,class,def,for,while,if,is,in,elif,else,not,and,or,print,break,continue,return,True,False,None,access,as,,del,except,exec,finally,global,import,lambda,pass,print,raise,try,assert},
keywordstyle={\color{Keywords}\bfseries},
% additional keywords
morekeywords={[2]@invariant},
keywordstyle={[2]\color{Decorators}\slshape},
emph={self},
emphstyle={\color{self}\slshape},
%
}}{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{afterpage}
\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm,headheight=2.1cm}
\exhyphenpenalty=10000\hyphenpenalty=10000
\makeatletter
\newcommand \Dotfill {\leavevmode \cleaders \hb@xt@ .77em{\hss .\hss }\hfill \kern \z@}
\renewcommand*\glspostdescription{\Dotfill}
\makeatother

\addbibresource{bibliography.bib}
\bibliography{refs} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title- & blank page
\begin{document}
\renewcommand{\thepage}{\roman{page}}
%%Mandatory blank page
\newpage
\thispagestyle{empty}
\mbox{}

\includepdf[pages={1}]{title-generated.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Copyright notice

\newpage{}\part*{Usage restrictions}

The author gives permission to make this master dissertation available for consultation 
and to copy parts of this master dissertation for personal use. 
 In the case of any other use, the copyright terms have to be respected, in particular with regard to 
the obligation to state expressly the source when quoting results from this master dissertation.

\pagebreak{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Preface

\newpage{}\part*{Preface}
\emph{\color{red}Dankwoord en zo verder.}
\pagebreak{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract

\newpage{}
\begin{abstract}
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Extended abstract
% Nog geen extended abstract
%\includepdf[pages={1,2}]{extended-abstract.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Table of Contents

\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% List of figures

\listoffigures
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% List of tables
% Nog geen tabellen
%\listoftables
%\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Used abbreviations and acronyms

\printglossary[type=\acronymtype,title={List of Acronyms}]
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Problem and background}
\renewcommand{\thepage}{\arabic{page}}
\setcounter{page}{1}

\newacronym{VHDL}{VHDL}{VHSIC Hardware Description Language}
\newacronym{VHSIC}{VHSIC}{Very High Speed Integrated Circuits}
\newacronym{TDD}{TDD}{Test Driven Development}
\newacronym{TFD}{TFD}{Test First Development}
\newacronym{CI}{CI}{Continuous Integration}

\section{Problem}

Developing \gls{VHDL}, like any code, is prone to error creation, either by user or by wrong product specifications. To ensure errors are weeded out before the more expensive production begins, the code must be subjected to rigorous testing. Currently, large and impractical tests are needed to fully test a product.
\\
\\
Because testing is such a time consuming process, finding errors often results in severe delays due to the need to both correct the error and test for others. Therefore it is in the best interests of both testing- and software engineers to write testbenches with maximal coverage, optimal readability and minimum time spent. It is also important to find and correct errors with minimal delay and maximal efficiency. This entire process should affect the least amount of code possible in order to minimize time spent retesting and modifying the code.
\\
\\
In this thesis, the objective is to provide VHDL users with an operating system independent framework. This framework will allow users to quickly and consistently create, modify and execute testbenches. To accomplish all of this, a number of tried and proven external tools will be gathered around a central Python script. This combination will ensure timely and automated building, testing and test report generation.

%In this thesis, a number of mechanics are used to optimize both testing and coding. Based loosely off %of \gls{TDD}, tests are written to function and be tested independently.  In order to maximize %coverage and keep the time spent writing tests to a minimum, a library with often used functions and %other useful code is made available. Alongside of it is a tool, written in Python, to process tests %independently  and represent the results in a quick and easy-to-read format.


\newpage{}


\section{Introduction}
\label{sec:intro}

\newacronym{CMOS}{CMOS}{Complementary Metal Oxide Semiconductor}
\subsection{Digital Electronics}

There are two kinds of electronic appliances and circuits; digital and analogue. Digital electronics differ from analogue electronics in that they use a discrete set of voltage levels to transmit signals. The most common number of items in the set is 2, a level for one (commonly
named \emph{high}) and a level for zero (commonly named \emph{ground} or \emph{low}). The advantage of using a discrete number of levels rather than a continuous signal as is used in analogue electronics, is that noise generated by the environment, thermal noise and other interfering factors will have but a minor influence on the signal.
\\
\\
To process these discrete signals, electronics are made up of transistors that nowadays are formed in with the \gls{CMOS} technology. This technology uses both an \emph{NPN} and a \emph{PNP} transistor that work in a push-pull configuration. The p's and n's in NPN and PNP simply stand for \emph{Positive} and \emph{Negative}. They are made of positively and negatively doped lumps of semiconductor, usually silicon-dioxide (SiO$_{2}$). A transistor is basically a blockage on a track and depending on the force applied to its \emph{gate}, it opens or closes the track.
\\
\\
In reality, the force takes the form of a current and an NPN transistor opens its gate when a positive current is applied. A PNP transistor, however, always leaves its gate open until a current is applied. This means that if we send the same signal to an NPN and a PNP transistor, with one of the signals inverted, we can open and close two parts of the entire circuit at the same time. This is useful to both direct a certain signal to ground and at the same time close its connection with the \emph{source} (the power source). Hence also the name \emph{Complementary} MOS, the NPN and PNP complement each other.
\\
\\
\newacronym{NAND}{NAND}{Not AND}
\newacronym{NOR}{NOR}{Not OR}
A certain combination of transistors is used to make \emph{logic gates}. These logic gates make sure that only a certain combination of ones and zeroes at the inputs result in certain ones or zeroes at the outputs. For instance, one of the most common logic gates is a \gls{NAND} gate. This gate has a number of inputs ranging from 2 to theoretically infinity (but practically 3 or 4) and only outputs a \emph{low} signal if all of the inputs are \emph{high} (digital one), otherwise its output is \emph{at ground} or \emph{low} (digital zero). The other most common logic gate is the \gls{NOR} gate. This gate outputs a low signal if any of its inputs are high, otherwise it outputs a low.
\\
\\
A common mistake is to think that low or ground mean \emph{zero voltage.} This is only partially true, the high signals are measured with ground as their reference. So a high signal of 1.8 V would be 1.8 V higher than ground, and could be considered to be at 1.8 V if ground is the theoretical zero. These logic gates are themselves combined to build higher-level blocks such as flip-flops, which are used to make registers and so on up to the entire chip design.

\pagebreak

\subsection{Hardware Description Languages}
\label{subsec:HDL}
\newacronym{HDL}{HDL}{Hardware Description Language}
\newacronym{RTL}{RTL}{Register Transfer Level}

A \gls{HDL} can be used to describe any one of the levels mentioned in the previous section, right down to the logic gate level. However, this last one is wholly unnecessary considering synthesis tools can produce superior logic gate-level layouts \cite{VHDLintro}. The level that uses certain blocks of logic gates to describe more complex behaviour is called the \gls{RTL}. Some blocks are standard implementations that have been widely used and are nearly fully optimized, such as memories, flip-flops and clocks. An \gls{RTL} flip-flop implementation written in \gls{VHDL} is shown here: 
\begin{lstlisting}[language=VHDL, tabsize=4, frame=single, framesep=2mm, belowskip=16pt, aboveskip=16pt, showstringspaces=false]
library IEEE;
use IEEE.std_logic_1164.all;
entity DFF is
	Port(D 	 : in std_logic;
		 CLK : in std_logic;
		 Q 	 : out std_logic;
end DFF;
architecture Behavioural of DFF is
begin
	process (CLK)
	begin
		if rising_edge(CLK) then
			Q <= D;
		end if;
	end process;
end Behavioural;
\end{lstlisting}

\newacronym{IEEE}{IEEE}{Institute of Electrical and Electronics Engineers}
\newacronym{DFF}{DFF}{D Flip-Flop}
The \gls{IEEE} library provides a number of extensions on the original \gls{VHDL} specification that allow a more realistic simulation and description of hardware behaviour. An \emph{entity} defines the inputs and outputs of a certain building block, in this case the \gls{DFF}. The D stands for Delay, and it simply puts on its output, Q, that which was on the input, D, one clock period earlier. The \emph{architecture}, in this case Behavioural, takes the description of an entity and assigns a real implementation to it. All \emph{processes} are executed in parallel, this does not mean that all are triggered at the same time, nor do they take equally as long to finish, but it means that any process can be executed alongside any other process. In this case there is only one (nameless) process that describes the entire behaviour of the flip-flop. The process waits for the rising edge of the clock, which is a transition from zero to one, after which it schedules the value of D to be put on Q when the next rising edge appears.
\\
\\
This is a basic example of an entity, an architecture and a process. This flip-flop could be used in certain numbers to build a \emph{register}, a collection of ones and zeroes (henceforth referred to as \emph{bits}) that is used to (temporarily) store these values. The register could then be used alongside combinational logic to build an even bigger entity. The idea here is that small building blocks can be combined to produce vast and complex circuits that are nearly impossible to describe in one go. Adding all these layers together also creates a lot of room for error, and having a multi-level design makes it challenging to pinpoint the exact level and location of any errors. Therefore, it is paramount that all code on all levels is tested thoroughly, which is done by use of \emph{testbenches} \cite{bergeron00}.
\\
\\
\newacronym{UUT}{UUT}{Unit Under Test}
\newacronym{DUT}{DUT}{Device Under Test}
Testbenches are made up of code that takes a certain building block, the \gls{UUT} or \gls{DUT}. The testbench then puts a certain sequence of values on the inputs and monitors the outputs. If the device performs normally, the received output sequence should match a certain \emph{golden reference}, the expected output sequence. In these testbenches it is good practice to observe how well a device performs if its inputs behave outside of the normal mode of operation. When all of these tests have finished and the output performs as expected, the device is ready to be put into production or further down the developmental process.
\\
\\
If a device is not tested properly and faults propagate throughout development, they can be very expensive to correct, especially at the stage of production, where a single photomask, used to ``print'' part of the layout, can easily cost \$100,000 (\euro81,000 at time of writing)\cite{weber06}. Therefore a large portion of time is spent writing and executing tests.

\begin{figure}[h]
    \centering
	\includegraphics[width=\textwidth]{images/VHDLflow.pdf}
    \caption{Typical CMOS design flow}
    \label{fig:Design_Flow}
\end{figure}

\newpage

%Wat zijn de gangbare praktijken in de industrie?
\newacronym{CRV}{CRV}{Constrained Random Verification}
\newacronym{DT}{DT}{Directed Testing}
\newacronym{FC}{FC}{Functional Coverage}
\newacronym{CC}{CC}{Code Coverage}
\newacronym{IC}{IC}{Intelligent Coverage}
\section{Current industry practices}
\label{sec:industry}
As mentioned before, a number of practices exist to improve speed and quality of testing and coding. The bigger part of these practices are applied in the software development industry, where this is quite literally their entire business. Moving to \gls{HDL}s, it stands to reason that code meant for synthesis may not be able to follow all of these best practices. However, the industry has formed several practices and \emph{methodologies} to try and create a uniform verification process. The most well-known will be discussed in some detail below.

\subsection{Assertions}
\label{subsec:assertions}
Assertions are the standard practice of verification. An assert in VHDL is very simple, check whether some boolean condition is true. If true, do nothing, if false, return the error message and throw an error of a certain level, as in the following example:
\begin{lstlisting}[language=VHDL, tabsize=4, frame=single, framesep=2mm, belowskip=8pt, aboveskip=8pt, showstringspaces=false]
assert (not Q) report "Unexpected output value" severity failure;
\end{lstlisting}
In this example, an error is thrown of the severity \emph{failure}, which ends the simulation, if the value on the output \emph{Q} (see subsection~\ref{subsec:HDL})) isn't \emph{logically true}. This means the output has to have a value of \emph{high} or \emph{1}. The severity of the assertion can be in the range of notice to failure, and the simulator might be set to respond or stop only to a certain level of severity. Doing this for the right values at intervals gives the developer a quick overview of whether everything went according to plan. After all, if things went wrong, the assertion should have thrown an error here or there.

\subsection{Coverage}
Coverage is a generic term that is used to describe how fully a design has been tested on one aspect or another. There exist many tools for different coverage analyses, but in this section we will focus only on the types of coverage.

\subsubsection{Code Coverage}
\newacronym{FSM}{FSM}{Finite State Machine}
In development, \gls{CC} is a type of measurement to indicate how well the source code has been tested. With the use of a coverage report, unused blocks of code can be uncovered, these blocks might indicate unnecessary code or a bug. Imagine a \gls{FSM} with an unused reset state, this might indicate that the reset isn't functioning properly or there are no tests covering the reset. CC does not, however, provide any real functional analysis. It does not indicate any missing lines of code nor does it tell you whether the inputs and outputs behave properly.

\subsubsection{Functional Coverage}
\gls{FC} is the practice of measuring whether design covers all possible use states it can possibly be in. Good practice is to include all possible cases, including corner cases, cases that cover multiple clock cycles, erroneous cases such as receiving an interrupt when processing or overflowing a buffer and so on. 

\subsection{Verification}

\subsubsection{Constrained Random Verification}
\gls{CRV} is an industry practice where one or more inputs are generated randomly, within certain bounds or \emph{constraints}. This practice was brought into use after designs grew too large for \gls{DT} to support. DT has verification engineers write out very specific things they wanted to test, for instance, a reset pulse to verify the reset working correctly. CRV opposes this with the idea that for all behaviour to be tested properly in large designs, the amount of time spent writing and executing tests would simply become too great. It proposes a solution where inputs are generated randomly, within certain bounds, but in a sufficiently large quantity to have implicitly covered all scenarios. It is important to note that in DT, expected behaviour is directly tested, but in CRV it is likely to be the unexpected behaviour that gets tested too. This solved the long standing problem of testing any and all behaviour, including the unexpected.

\subsubsection{Formal Verification}
On top of the aforementioned, there are several more practices that have unique ways of verifying the properties of a design, but aren't used sufficiently to merit full detailing. Formal verification is such a practice, where the core idea is to mathematically prove the design from its specifications. The upside is that the design is completely verified, however, it it out of use because proving large designs is not only tedious but takes up ridiculous amounts of man-hours.

\subsection{Methodologies}

\subsubsection{Open Source VHDL Verification Methodology}
\newacronym{OSVVM}{OSVVM}{Open Source VHDL Verification Methodology}
The \gls{OSVVM} is a set of packages that makes it easier for \gls{CRV} and \gls{FC} to be implemented in a project. It consists out of two packages, \emph{Random.pkg} and \emph{Coverage.pkg}. The new feature, which it dubs \gls{IC}, redefines its FC model based on holes in the FC coverage and randomization. The advantage is obviously that 100\% coverage is always within reach, even when the original draft did not achieve full coverage.\cite{ICoverage}

\subsubsection{Universal Verification Model}
\emph{\color{red} To be written!}

\subsection{Simulation tools}
As mentioned in section~\ref{sec:intro} \gls{HDL}s are used for developing hardware, and need to be tested and build as such. Like any other programming language, they need a dedicated compiler to fault-check the code and build the binaries. Unlike other programming languages, however, they need a simulator in order to verify the builds. There exist many compilers and simulators, almost none are exclusive for \gls{VHDL}, almost all are dual-language and support some form of Verilog, a different HDL. However, many of them refuse to support the latest additions to the VHDL language specification, even the 2002 additions are hard to be found.

\label{subsec:simtool}
\subsubsection{ModelSim}
ModelSim is the simulator that was investigated for several reasons. First, a free student edition was available. Considering licenses  outside of school can easily cost upward of \$25,000 (\euro20,250 at time of writing) this made it ideal for any thesis or student related work. Proof of this is the extensive use of ModelSim in the courses related to HDL development. Second, ModelSim supports all versions of \gls{VHDL}, which is the \gls{HDL} we are processing. Even in 2014, only one other tool was found to support all of VHDL-2008. And last but not least, ModelSim is one of the industry's most used simulators, enabling a pool of experience to be consulted.

\emph{\color{red}Figuurtje of vergelijking tussen simulators?}

%Wat is CI? Wat doet Hudson?
%GIT? Hoe werkt het, waarom?
%Waarom automated? Voordelen?
%Problemen bij implementatie? Tekortkomingen?

\section{Software development \& practices}
During the making of this thesis, a number of approaches was investigated and some were put to practical use. In this chapter, the more useful and tried of the aforementioned are discussed in some detail.


\subsection{Test Driven Development}
\gls{TDD} is a proven development technique that has regained traction in the past decade, primarily through the efforts of Kent Beck\cite{VHDLUnit}. This practice has proven to increase test coverage \cite{Siniaalto:2007:CCS:1302496.1302946}, decrease defect density \cite{TDDinpractice} as well as improve code quality \cite{TDDinpractice,conf/isese/BhatN06}. The technique focuses on tests being created before the actual code. It is important to make certain distinctions before going more in depth on the used methods. The developing community has a great many practices, each with their own names and methods, and hardly none are mutually exclusive.

\subsubsection{Unit Testing}
To understand \gls{TDD}, an basic knowledge of \emph{Unit Testing} is required. In software testing, a unit test is a test designed to check a single unit of code. Ideally, this unit is the smallest piece in which the code can be divided. A unit test should always test only a single entity, and only one aspect of that entity's behaviour. This division in units has a number of benefits, one of the most important being that code is exceedingly easy to maintain. Furthermore, the division of the code makes changes, when needed, fast to be carried out and ensures that only the modified code needs to re-tested.

%% herschrijven!
\subsubsection{Test First Development}
Another main component of \gls{TDD} is \gls{TFD}, a technique that has a developer writing tests first, before any code has been written. This method makes the developer think on what the code has to achieve, rather than what the specific implementation has to be. A key feature of a new test is that it has to fail during its first run. If not, the test is obsolete seeing as the functionality it tests has already been implemented. After being run for the first time (and failing), the developer implements just enough code to get the test to pass. Once the test succeeds, it is time for a new test.

\subsubsection{Refactoring}
The third pillar of TDD is refactoring. After the tests succeed, it is necessary to clean up the code. A well-done \gls{TFD} implementation uses the bare amount of code needed to make the test pass, but this is of course usually not the best code possible. Refactoring means that you take existing code and modify only the code itself to perform better. This leaves both the input and output of the tests and code unchanged, only the way the code processes input is altered. It is important in this step to edit nothing in the test code or the outputs or inputs. Otherwise, either the test would behave differently or new tests would have to be written. The latter goes directly against the \gls{TFD} principle.

\subsubsection{Test Driven Development}
Test Driven Development is a combination of the previously mentioned techniques. A Unit Test is written before any code, the test is then executed and should fail. After the failure, the most basic code to make the test pass is implemented, the test is then executed again and should pass. After this first pass, the code written for the passing of the test, and only this code, is edited to perform and look better. This follows all steps mentioned above, a \emph{Unit Test} is written according to \emph{Test First Development} and is \emph{Refactored} later.

\begin{figure}[h]
    \centering
	\includegraphics[width=0.38\textwidth]{images/tdd.pdf}
    \caption{Three step TDD design flow}
    \label{fig:TDD_Flow}
\end{figure}

\subsection{Continuous Integration}
\gls{CI} is a software development technique in which developers upload the edits on the software, or their \emph{build}, to a central server which then \emph{continuously integrates} the code from multiple developers. This to prevent integration headaches when the code of multiple developers has diverged to such an extent that it would take much more time to make the edits work together than if they had been integrated early on.

\subsubsection{Revision Control}
\newacronym{RC}{RC}{Revision Control}
There are many aspects to a properly maintained \gls{CI} system, but one key aspect of overall programming has to be \gls{RC}. Not to be confused with the "undo" button in your preferred editor, a good \gls{RC} system does allow for any and all mistakes made over different edits to be undone with very little work. There exist many systems for revision control, but they all have in common that they track changes one way or the other, and most importantly that these changes can be undone. 

\subsubsection{Build Automation}
A useful but not required aspect is build automation. Using a timer or trigger, the build automatically runs with the latest updates, preferably from an \gls{RC} system. This way, the binaries are always up to date and the developer does not need to wait for compilation to run the latest tests. Although the latter is less imported in a proper \gls{CI} system as will be discussed further on. 

\subsubsection{Test Automation}
As the code is build at scheduled times, and testing is needed regardless it makes perfect sense to add a testing step to the automated build. Automating tests saves the developers yet another part of their time, thus freeing more for the actual development and debugging steps. A good \gls{CI} system can read test reports, or at least some standard of reports. 

\subsubsection{Hudson-CI}
Combining all of these practices saves developers a lot of time and, by extension, the company they might work for, a lot of money. Considering today's competitive market for software development, any edge that can be obtained is a plus. Even more so when plenty of free Continuous Integration servers exist that employ open or widely used standards. The \gls{CI} solution that was investigated is Hudson-CI. Hudson-CI provides an extensive range of features, including everything listed above. The used features are:
\begin{itemize}
\item Timed and triggered building from an \gls{RC} repository.
\item Automated testing of said build.
\item Humanly readable reports in the \emph{JUnit} format.
\item Graphical and statistical overview of test progress throughout builds.
\end{itemize}

\subsection{JUnit}
\newacronym{XML}{XML}{eXtensible Markup Language}
JUnit is an implementation for the Java programming language of the xUnit specification, which defines several key components for a testing framework. Considering the relevance here is not the framework itself but the format used for its reports, details about its implementation and use will not be discussed.\\
The JUnit reports are written in \gls{XML}, which is a type of language used for formatting data. The JUnit format is supported by numerous (open source) tools, such as Eclipse and the aforementioned Hudson-CI, which makes it an ideal candidate for further investigation. 

\subsection{Python}
Python is a high-level computer programming language that first appeared in 1991, with the third major revision being released in 2008. It supports object-oriented and structured programming, and is easy to use as a scripting language. A great feat of Pythons community is that there are many, many (open source) libraries available for just about any function that comes to mind. This is on top of the already impressive amount of libraries Python itself supports. In addition to this, Python has all of its standard features explained in great detail with good examples in its online documenting system. The combination of these features allows any programmer, even with very little know-how, to quickly put together anything that comes to mind.

%Kan VHDL gemakkelijk ontwikkeld worden met Continuous Integration?
%Wat is ModelSim, waarom gebruiken? Mogelijke opties/voordelen? gratis studentenversie
%Wat is BitVis? Hoe helpt dit? 
%Wat is het marktaandeel van VHDL?
%Wat doet VHDL bij een testbench? Specialiteitjes waar er op gelet moet worden?
%Wat is de gemiddelde looptijd van een groot project?

\newpage
\part{Developing a framework}
In part I different aspects from both the software and \gls{VHDL} development worlds were discussed, each in  varying levels of detail. In this part bits and pieces of each subject are combined to form a new whole, a VHDL development framework.

\section{Outlining}
Before work begins on developing the framework, there need to be some bounds set and goals to work towards. As VHDL development is done in both Windows and Linux environments, it only makes sense to keep the whole framework as platform independent as possible. To add to this, the whole needs to be developed in the short span of under a year by one developer who has had little experience doing so. The language chosen thus must be easy to master and work on all platforms with as few as possible modifications.\\
\\
Furthermore, software practices will have to be applied to maintain clean code and a steady development process. To this end, work started with unit testing in mind. Parts of the VHDL testbench are separated to be executed independently in an automated fashion.

\subsection{First draft}
In section~\ref{sec:industry} some current industry practices were discussed and one of the very basic VHDL testing methods was found to be assertions. In order to remain as broad as possible, work started with processing these assertions first. The assertions thus need to be found inside the VHDL testbench, separated and saved in individual files to be executed.\\
\\
One of the main problems that quickly arose was: \emph{Where are the assertions located?}. To prevent overcomplicating things, the assumption was made that all tests are fitted inside their own procedure or function and that these would be called from inside the architecture body. All that would remain was to find the architecture body, find the keyword \emph{begin} and extract every line from the body.\\
\\
When the script was run on a file, a few problems quickly came in view:
\begin{itemize}
\item Tests can be a lot more complicated than first assumed
\item Procedures and functions aren't that easily made to contain fully working code
\item Writing tests this way is actually \emph{more} time consuming
\end{itemize}
To try and counter the problems, making use of a standardized function library was proposed. This way, verified code could be integrated which reduced the workload when writing the testbench. Making use of this library would also bring a degree of uniformity to the testbenches, which would help with readability.

\newpage{}
\subsection{First improvements}
As mentioned above, one of the first improvements was a standardized function library. To be of any use, this library should contain functions and procedures that are either used extensively throughout the developmental process, have a great potential of being used or that, when created on their own, would impose a significant workload on the developer. Considering the large percentage of the industry still working in the VHDL-93 specification, the library would need to be compatible with this version. However, to ensure future usability and steer development towards the newer versions, i.e. 2002 and 2008, these will need to be supported as well.\\
\\
A second improvement, yet undiscussed, would be maintaining a clean set-up. Throughout the first testing, it became apparent that when multiplying the amount of testbenches that are executed, the files around them are multiplied in the same way. Massive clutters of 'temporary' files and folders would quickly pollute the workspace, and thus keeping track and removing unneeded files would be of the essence, especially considering later modifications (see subsection~\ref{subsec:CI}).

\subsubsection{The Library}
The first addition to the library was the tracking of signals and arrays (called \emph{vectors} in VHDL). VHDL itself provides assertion-based verification, as mentioned before subsection~\ref{subsec:assertions}). However, these assertions are long and nondescript. To make these easier to read and reproduce, functions could be made that act the same as a well-written assertion, but are much easier to read. Furthermore, assertions can be used to pass information about non-critical signals to a shell environment that looks for specific output text. An example:

\begin{multicols}{2}
\begin{lstlisting}[language=VHDL, tabsize=4, frame=single, framesep=2mm, belowskip=8pt, aboveskip=8pt, showstringspaces=false, basicstyle=\footnotesize]
procedure reportBack(
	b : boolean;  result : string) is
begin
	if (not Q) then
		assert false report
			"test success" & ht & "name: "
			& "Checking Q" severity note;
	else
		assert false report
			"test failed" & ht & "name: "
			& "Checking Q" severity note;
	end if;
end procedure;
\end{lstlisting}
\columnbreak
\begin{lstlisting}[language=VHDL, tabsize=4, frame=single, framesep=2mm, belowskip=8pt, aboveskip=8pt, showstringspaces=false, basicstyle=\footnotesize]
 wait until rising_edge(clk);
 reportback(('0' = Q), "Checking Q:1");
 wait until rising_edge(clk);
 reportback(('1' = Q), "Checking Q:2");
 wait until rising_edge(clk);
 reportback(('0' = Q), "Checking Q:3");
 wait until rising_edge(clk);
 reportback(('1' = Q), "Checking Q:4");
 wait until rising_edge(clk);
 reportback(('0' = Q), "Checking Q:5");
 wait until rising_edge(clk);
 reportback(('1' = Q), "Checking Q:6");
 wait until rising_edge(clk);
\end{lstlisting}
\end{multicols}
In the left column, the source code of the function used in the right column is displayed. It is easy to see that, to maintain the same level of useful information (report on success \emph{and} failure, name of test) without a procedure, the code would be excessively long. On top of that, the readability is improved greatly with only the logic and the message to display remaining. If this much improvement comes from a very simple function, it is not unlikely that a great deal more can come should the library be expanded.

\subsubsection{Cleaning up}
The second addition, simultaneous with the first, is the implementation of a clean-up system. As mentioned before, a massive amount of 'compiled clutter' is created when tests are separated into multiple testbenches. Several ways of dealing with this were considered, such as:
\begin{itemize}
\item Tracking changes in the working directory
\item Filtering needed files and deleting everything else
\item Compiling in a specific folder and extracting what was needed
\end{itemize}
Each of these methods has its advantages and disadvantages, but to begin the second method was chosen. This was easy to do, considering compiling happened in a local folder and all the files that were being used were known. The disadvantage being that, if the files used should change and this is not implemented in the code, it would result in the loss of these files.

\subsection{Code execution}
With many files being generated and every file test by hand, an automated compile and test system had to be devised. As discussed in subsection~\ref{subsec:simtool}, ModelSim was deemed the most useful tool for this development. As many tools do, ModelSim supports command-line execution of its commands, even easier to invoke should the tool be added to the system's \emph{path} variable. Python, being a script language, fully supported execution of command-line code with it's built-in function \emph{os.system()}, an example:
%\begin{lstlisting}[tabsize=4, frame=single, framesep=2mm, belowskip=8pt, aboveskip=8pt, showstringspaces=false, language=python]
%\end{lstlisting}

\begin{python}
os.system('vlib work')
os.system('vcom -2008 -work work tb_dff.vhd')
os.system('vsim -c work.tb_dff(Behavioural) -do "run -all;exit"')
\end{python}

In the above example, the VHDL library \emph{work} is made, the file \emph{tb\_dff.vhd} is compiled to it and the architecture \emph{Behavioural} of tb\_dff is executed with the options \emph{"run -all;exit"} (This means as much as \emph{run from start to end, then exit the program}.). Work is a standard name for a library, but it is prone to abuse, i.e. putting everything in the work library. Nevertheless, this is a script that is being executed and as such generic names aren't a problem for the script itself, only for debugging by the developer. the -2008 and -c flags indicate the VHDL-2008 version is being used and that the tool works in command line mode.\\
\\
To summarize, the script now took a testbench, separated its tests into different testbench files, compiled and executed each of these files and displayed the output in the console used to execute the script from. So some tasks are automated, but there still isn't any clear overview of results nor is there full automation.


\subsection{Code organisation}
The next step in the process was code organisation. Up until now everything was being done sequentially in the main Python file. With the come become increasingly complex and to increase the above promoted readability, functions were made to contain their own parts of the code.

% Voor later:
% ultimately the third option was deemed the most suitable. The main disadvantage of this method %is that making uniform folder tracking platform independent is not very easy. Thankfully, Python %has some folder variables that are suitable for this case.

\subsection{Hudson-CI}
\label{subsec:CI}\emph{\color{red}Sectietje over hudson (nodig om te verwijzen)}

\newpage{}
\section{The future of testing}
\emph{\color{red} Iets over VHDL features, verbeteringen etc}
%Wat zijn de ontbrekende features voor het geavanceerd testen van VHDL?
%Wat kan er verbeterd worden aan de VHDL specificatie?
%Hoe kunnen de programmas (compilers e.d.) aangepast worden zodat dit overkomen wordt?

\newpage{}
\section{Conclusion}
%Wat hebben we gedaan en hoe hebben we het bereikt? (beknopte versie)
%-> State facts

\pagebreak{}

\printbibliography

%\begin{thebibliography}{1}
%\bibitem{key-1}http://www.asic-world.com/vhdl/intro1.html
%
%\bibitem{key-2}Writing Testbenches: Functional Verification of HDL Models
%
%\bibitem{key-3}Mask Cost and Profitability in Photomask Manufacturing: An Empirical Analysis
%
%\bibitem{key-4}Citation needed !!
%
%\bibitem{key-5}A comparative case study on the impact of test-driven development on program design and test coverage
%
%\bibitem{key-6}A Longitudinal Study of the Use of a Test-Driven Development Practice in Industry
%
%\bibitem{key-7}Evaluating the Efficacy of Test-Driven Development
%
%\bibitem{key-8}http://martinfowler.com/bliki/UnitTest.html
%
%\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 

%\newpage{}
%\begin{landscape}
%\part{Appendix}
%\section*{Code}
%\lstinputlisting[language=Python, basicstyle=\tiny]{H:/Users/Joren/Documents/GitHub/VHDL/src/%testbench_parser.py}
%\end{landscape}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Mandatory blank page
\afterpage{\blankpage}


\end{document}
